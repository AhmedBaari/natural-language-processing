{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presented by Ahmed Baari on 25 October 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can BERT do?\n",
    "In this notebook, let's explore the capabilities of BERT by using it for a variety of NLP tasks. We will use the `transformers` library to load a fine-tuned BERT model and use it for the following tasks:\n",
    "1. Text Classification\n",
    "2. Named Entity Recognition\n",
    "3. Question Answering\n",
    "4. Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline('text-classification',\n",
    "                              model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "                              tokenizer='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "                              device=0) # 0 is the GPU index\n",
    "\n",
    "sentiment_pipeline.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.8126146197319031}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline('NLP Class is amazing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '4 stars', 'score': 0.45880571007728577}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline('NLP Class is actually good')\n",
    "sentiment_pipeline('NLP Class is good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.7211390733718872}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline('NLP Class is okay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '2 stars', 'score': 0.46322232484817505}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline('NLP Class is boring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1 star', 'score': 0.7699272036552429}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline('NLP Class is terrible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': '1 star', 'score': 0.054048508405685425},\n",
       "  {'label': '2 stars', 'score': 0.08055774867534637},\n",
       "  {'label': '3 stars', 'score': 0.15945588052272797},\n",
       "  {'label': '4 stars', 'score': 0.36899498105049133},\n",
       "  {'label': '5 stars', 'score': 0.3369428813457489}]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline('The 5th semester has finally come to an end', return_all_scores=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "Extract entities such as organizations, locations, or individuals from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The Shanmugha Arts, Science, Technology & Research Academy, also known as SASTRA, is a private and deemed university in the town of Thirumalaisamudram, Thanjavur district, Tamil Nadu, India. SASTRA is ranked by global ranking agencies such as Times Higher Education and QS. It offers undergraduate, post graduate and doctoral courses in Engineering, Science, Education, Management, Law and the Arts.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG',\n",
       "  'score': 0.97421646,\n",
       "  'word': 'Shanmugha Arts, Science, Technology & Research Academy',\n",
       "  'start': 4,\n",
       "  'end': 58},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99745464,\n",
       "  'word': 'SASTRA',\n",
       "  'start': 74,\n",
       "  'end': 80},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9783507,\n",
       "  'word': 'Thirumalaisamudram',\n",
       "  'start': 132,\n",
       "  'end': 150},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.97977877,\n",
       "  'word': 'Thanjavur',\n",
       "  'start': 152,\n",
       "  'end': 161},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.997586,\n",
       "  'word': 'Tamil Nadu',\n",
       "  'start': 172,\n",
       "  'end': 182},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9825057,\n",
       "  'word': 'India',\n",
       "  'start': 184,\n",
       "  'end': 189},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9949009,\n",
       "  'word': 'SASTRA',\n",
       "  'start': 191,\n",
       "  'end': 197},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99622416,\n",
       "  'word': 'Times Higher Education',\n",
       "  'start': 243,\n",
       "  'end': 265},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9934008,\n",
       "  'word': 'QS',\n",
       "  'start': 270,\n",
       "  'end': 272}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = ner_pipeline(text, aggregation_strategy=\"simple\")\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shanmugha Arts, Science, Technology & Research Academy: ORG (0.97)\n",
      "SASTRA: ORG (1.00)\n",
      "Thirumalaisamudram: LOC (0.98)\n",
      "Thanjavur: LOC (0.98)\n",
      "Tamil Nadu: LOC (1.00)\n",
      "India: LOC (0.98)\n",
      "SASTRA: ORG (0.99)\n",
      "Times Higher Education: ORG (1.00)\n",
      "QS: ORG (0.99)\n"
     ]
    }
   ],
   "source": [
    "for entity in entities:\n",
    "    print(f\"{entity['word']}: {entity['entity_group']} ({entity['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"question-answering\",\n",
    "                       device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was July 2019 when I, a child, was about to watch the livestream of an Indian rocket launch for t'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\n",
    "with open(\"chandrayaan.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8325778245925903\n",
      "start: 4682\n",
      "end: 4698\n",
      "answer: The Soviet Union\n"
     ]
    }
   ],
   "source": [
    "question = \"Who found water on the moon?\"\n",
    "\n",
    "outputs = qa_pipeline(question=question, context=text)\n",
    "\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "summarization_pipeline = pipeline(\"summarization\",\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Chandrayaan-2 is India's prestigious moon mission to map and study the variations in lunar surface composition, as well as the location and abundance of lunar water. The Chandraysaan Series is the names of India's lunar exploration missions. Each mission had different objectives and achievements, but they all shared the common goal of advancing India's scientific and technological capabilities in space.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = summarization_pipeline(text[:1023], clean_up_tokenization_spaces=True)\n",
    "\n",
    "summary = outputs[0]['summary_text']\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "wrapper = textwrap.TextWrapper(width=80, break_long_words=False, break_on_hyphens=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chandrayaan-2 is India's prestigious moon mission to map and study the\n",
      "variations in lunar surface composition, as well as the location and abundance\n",
      "of lunar water. The Chandraysaan Series is the names of India's lunar\n",
      "exploration missions. Each mission had different objectives and achievements,\n",
      "but they all shared the common goal of advancing India's scientific and\n",
      "technological capabilities in space.\n"
     ]
    }
   ],
   "source": [
    "print(wrapper.fill(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There's Much More!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-classification\n",
      "automatic-speech-recognition\n",
      "text-to-audio\n",
      "feature-extraction\n",
      "text-classification\n",
      "token-classification\n",
      "question-answering\n",
      "table-question-answering\n",
      "visual-question-answering\n",
      "document-question-answering\n",
      "fill-mask\n",
      "summarization\n",
      "translation\n",
      "text2text-generation\n",
      "text-generation\n",
      "zero-shot-classification\n",
      "zero-shot-image-classification\n",
      "zero-shot-audio-classification\n",
      "image-classification\n",
      "image-feature-extraction\n",
      "image-segmentation\n",
      "image-to-text\n",
      "object-detection\n",
      "zero-shot-object-detection\n",
      "depth-estimation\n",
      "video-classification\n",
      "mask-generation\n",
      "image-to-image\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipelines\n",
    "for task in pipelines.SUPPORTED_TASKS:\n",
    "    print(task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
